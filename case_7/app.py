import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from textblob import TextBlob
from io import BytesIO
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.decomposition import LatentDirichletAllocation
import base64

# 0. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="Amazon Reviews Dashboard",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("üõí Amazon US Product Reviews Dashboard")
st.markdown("–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑ –æ—Ç–∑—ã–≤–æ–≤ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ Hugging Face (3‚ÄØ–ì–ë) –±–∞—Ç—á–∞–º–∏.")

# 1. –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ c –ø—Ä–æ–≥—Ä–µ—Å—Å‚Äë–±–∞—Ä–æ–º
@st.cache_data(show_spinner=True)
def load_data(url, chunksize=200_000):
    dtype = {
        "product_title": "category",
        "product_category": "category",
        "star_rating": "int8",
        "helpful_votes": "int16",
        "total_votes": "int16",
        "verified_purchase": "category",
        "review_body": "str",
        "review_date": "str"
    }
    progress = st.progress(0.0, text="–ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞—Ç—á 0‚Ä¶")
    chunks = []
    it = pd.read_csv(url, chunksize=chunksize, dtype=dtype, low_memory=False)
    total = int(3_000_000 / chunksize) + 1  # –≥—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞ —á–∏—Å–ª–∞ –±–∞—Ç—á–µ–π
    for i, chunk in enumerate(it):
        chunks.append(chunk)
        progress.progress((i+1)/total, text=f"–ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞—Ç—á {i+1} –∏–∑ {total}‚Ä¶")
    df = pd.concat(chunks, ignore_index=True)
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
    df['review_date'] = pd.to_datetime(df['review_date'], errors='coerce')
    df['year_month'] = df['review_date'].dt.to_period('M').astype(str)
    df['sentiment_simple'] = df['star_rating'].apply(
        lambda r: 'negative' if r<=2 else 'neutral' if r==3 else 'positive'
    )
    df['polarity'] = df['review_body'].fillna("").map(
        lambda t: TextBlob(t).sentiment.polarity
    )
    return df

CSV_URL = (
    "https://huggingface.co/datasets/PbI4a/Case_7/"
    "resolve/main/case_7/clean_reviews.csv"
)
with st.spinner("–ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ‚Ä¶"):
    df = load_data(CSV_URL)

# 2. –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
st.sidebar.header("üîç –§–∏–ª—å—Ç—Ä—ã")
years = sorted(df['review_date'].dt.year.dropna().unique().astype(int))
yr_min, yr_max = st.sidebar.select_slider(
    "–ì–æ–¥ –æ—Ç–∑—ã–≤–∞", options=years, value=(years[0], years[-1])
)
ratings = st.sidebar.multiselect(
    "–†–µ–π—Ç–∏–Ω–≥ (–∑–≤—ë–∑–¥—ã)", [1,2,3,4,5], default=[1,2,3,4,5]
)
products = st.sidebar.multiselect(
    "–ü—Ä–æ–¥—É–∫—Ç—ã (–¥–æ 5)", df['product_title'].dropna().unique(), max_selections=5,
    default=df['product_title'].dropna().unique()[:3]
)
verified = st.sidebar.checkbox("–¢–æ–ª—å–∫–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥—ë–Ω–Ω—ã–µ –ø–æ–∫—É–ø–∫–∏", value=False)

mask = (
    (df['review_date'].dt.year >= yr_min) &
    (df['review_date'].dt.year <= yr_max) &
    (df['star_rating'].isin(ratings))
)
if products:
    mask &= df['product_title'].isin(products)
if verified:
    mask &= df['verified_purchase']=='Y'
df = df[mask]

# 3. –ù–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–∞–±—ã
tabs = st.tabs([
    "Overview","Sentiment","Time Series","Comparison",
    "Text Analysis","Clustering","Topic Modeling","Reviews","Export"
])

# --- Overview
with tabs[0]:
    st.header("üìä –û–±–∑–æ—Ä")
    c1, c2, c3 = st.columns(3)
    c1.metric("–û—Ç–∑—ã–≤—ã –≤—Å–µ–≥–æ", f"{len(df):,}")
    c2.metric("–°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥", round(df['star_rating'].mean(),2))
    c3.metric("–°—Ä–µ–¥–Ω—è—è –ø–æ–ª—è—Ä–Ω–æ—Å—Ç—å", round(df['polarity'].mean(),2))
    fig = px.histogram(
        df, x='star_rating', nbins=5,
        title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–π—Ç–∏–Ω–≥–æ–≤"
    )
    st.plotly_chart(fig, use_container_width=True)

# --- Sentiment
with tabs[1]:
    st.header("üí¨ –¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å")
    simple = df['sentiment_simple'].value_counts().reset_index()
    simple.columns = ['sentiment','count']
    fig1 = px.pie(
        simple, names='sentiment', values='count',
        title="–ü–æ —Ä–µ–π—Ç–∏–Ω–≥—É",
        color='sentiment',
        color_discrete_map={'positive':'green','neutral':'gray','negative':'red'}
    )
    fig2 = px.histogram(
        df, x='polarity', nbins=30, title="TextBlob –ø–æ–ª—è—Ä–Ω–æ—Å—Ç—å"
    )
    st.plotly_chart(fig1, use_container_width=True)
    st.plotly_chart(fig2, use_container_width=True)

# --- Time Series
with tabs[2]:
    st.header("‚è≥ –î–∏–Ω–∞–º–∏–∫–∞ –≤–æ –≤—Ä–µ–º–µ–Ω–∏")
    grp = df.groupby('year_month').agg(
        reviews=('star_rating','count'),
        avg_rating=('star_rating','mean')
    ).reset_index()
    fig1 = px.bar(grp, x='year_month', y='reviews', title="–û—Ç–∑—ã–≤—ã –ø–æ –º–µ—Å—è—Ü–∞–º")
    fig2 = px.line(grp, x='year_month', y='avg_rating', title="–°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥")
    st.plotly_chart(fig1, use_container_width=True)
    st.plotly_chart(fig2, use_container_width=True)

# --- Comparison
with tabs[3]:
    st.header("üîÄ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–æ–≤")
    sel = st.multiselect(
        "–ü—Ä–æ–¥—É–∫—Ç—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è", products,
        default=products[:3], max_selections=5
    )
    comp = df[df['product_title'].isin(sel)].groupby(
        ['product_title','year_month']
    )['star_rating'].mean().reset_index()
    fig = px.line(
        comp, x='year_month', y='star_rating', color='product_title',
        title="–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–π –æ—Ü–µ–Ω–∫–∏"
    )
    st.plotly_chart(fig, use_container_width=True)

# --- Text Analysis
with tabs[4]:
    st.header("üìù –¢–µ–∫—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑")
    sel_s = st.selectbox("–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –æ–±–ª–∞–∫–∞", ['positive','neutral','negative'])
    txt = " ".join(df[df['sentiment_simple']==sel_s]['review_body'].dropna())
    wc = WordCloud(width=800, height=300, background_color="white").generate(txt or " ")
    fig, ax = plt.subplots(figsize=(10,3))
    ax.imshow(wc, interpolation='bilinear'); ax.axis("off")
    st.pyplot(fig)
    st.subheader("–¢–æ–ø‚Äë20 —Å–ª–æ–≤ –∏ –±–∏–≥—Ä–∞–º")
    tokens = pd.Series(" ".join(df['review_body'].dropna()).lower().split())
    topw = tokens.value_counts().head(20).reset_index()
    topb = pd.Series(zip(tokens, tokens.shift(-1))).value_counts().head(20).reset_index()
    topb.columns=['bigram','count']
    fig1 = px.bar(topw, x='count', y='index', orientation='h', title="–¢–æ–ø-20 —Å–ª–æ–≤")
    fig2 = px.bar(topb, x='count', y='bigram', orientation='h', title="–¢–æ–ø-20 –±–∏–≥—Ä–∞–º")
    st.plotly_chart(fig1, use_container_width=True)
    st.plotly_chart(fig2, use_container_width=True)

# --- Clustering
with tabs[5]:
    st.header("üîç –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –æ—Ç–∑—ã–≤–æ–≤")
    n_clusters = st.slider("–ß–∏—Å–ª–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤", 2, 10, 4)
    vect = TfidfVectorizer(max_features=5000, stop_words='english')
    X = vect.fit_transform(df['review_body'].fillna(""))
    km = KMeans(n_clusters=n_clusters, random_state=42).fit(X)
    df['cluster'] = km.labels_
    cnt = df['cluster'].value_counts().sort_index().reset_index()
    cnt.columns=['cluster','count']
    fig = px.bar(cnt, x='cluster', y='count', title="–ö–ª–∞—Å—Ç–µ—Ä—ã –ø–æ —Ä–∞–∑–º–µ—Ä—É")
    st.plotly_chart(fig, use_container_width=True)
    terms = vect.get_feature_names_out()
    order = km.cluster_centers_.argsort()[:, ::-1]
    for i in range(n_clusters):
        st.markdown(
            f"**–ö–ª–∞—Å—Ç–µ—Ä {i}:** " +
            ", ".join(terms[idx] for idx in order[i, :10])
        )

# --- Topic Modeling
with tabs[6]:
    st.header("üìÇ –¢–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (LDA)")
    n_topics = st.slider("–ß–∏—Å–ª–æ —Ç–µ–º", 2, 10, 4)
    vect2 = TfidfVectorizer(max_features=2000, stop_words='english')
    X2 = vect2.fit_transform(df['review_body'].fillna(""))
    lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)
    lda.fit(X2)
    terms2 = vect2.get_feature_names_out()
    for idx, topic in enumerate(lda.components_):
        top_terms = [terms2[i] for i in topic.argsort()[-10:][::-1]]
        st.markdown(f"**–¢–µ–º–∞ {idx}:** " + ", ".join(top_terms))

# --- Reviews (–ø–∞–≥–∏–Ω–∞—Ü–∏—è)
with tabs[7]:
    st.header("üìÑ –ü—Ä–æ—Å–º–æ—Ç—Ä –æ—Ç–∑—ã–≤–æ–≤")
    page_size = st.number_input("–û—Ç–∑—ã–≤—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É", 5, 50, 10)
    total = len(df)
    pages = (total // page_size) + 1
    page = st.number_input("–°—Ç—Ä–∞–Ω–∏—Ü–∞", 1, pages, 1)
    start = (page-1)*page_size
    subset = df.iloc[start:start+page_size][[
        'review_date','product_title','star_rating','review_body'
    ]]
    for _, row in subset.iterrows():
        with st.expander(
            f"{row['review_date'].date()} | ‚≠ê {row['star_rating']} | "
            f"{row['product_title'][:30]}"
        ):
            st.write(row['review_body'])

# --- Export
with tabs[8]:
    st.header("üíæ –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö")
    csv = df.to_csv(index=False).encode('utf-8')
    st.download_button("–°–∫–∞—á–∞—Ç—å CSV", data=csv,
                       file_name="filtered_reviews.csv", mime="text/csv")
    html = df.to_html()
    b64 = base64.b64encode(html.encode()).decode()
    href = (
        f'<a href="data:text/html;base64,{b64}" download="reviews.html">'
        "–°–∫–∞—á–∞—Ç—å HTML-–æ—Ç—á—ë—Ç</a>"
    )
    st.markdown(href, unsafe_allow_html=True)
